## ğŸ“šToken-Guided Self-Supervised Temporal Reconstruction

A diffusionâ€‘transformer framework that turns **3â€‘hourly or hourly reanalyses into 15â€‘minute fields** without highâ€‘frequency labels.  
The package contains:

* PyTorchâ€¯+â€¯Diffusers code (`src/`)
* example experiment files (`configs/`)
* data stubs (`data/`)
* publicationâ€‘quality figures (`pics/`)

> **Highlights**
>
> - **Labelâ€‘free temporal superâ€‘resolution**: a diffusion UNet is trained purely on coarse reanalysis sequences, learning to reconstruct subâ€‘hourly dynamics from hourly or 3â€‘hourly inputs without any highâ€‘frequency ground truth.
> - **Tokenâ€‘conditioned control**: discrete tokens that encode calendar date, seasonal phase and requested leadâ€‘time enter each crossâ€‘attention block, allowing the user to specify arbitrary target intervals (e.g.,â€¯+15â€¯min, +30â€¯min) in a single forward pass.
> - **Historic reanalysis upgrade**: after ERA5â€‘Land preâ€‘training the model is fineâ€‘tuned on NOAAâ€‘20CRâ€¯v3; it delivers a global 15â€‘min surfaceâ€‘layer data set for 1806â€‘1910, opening new possibilities for extremeâ€‘event attribution and earlyâ€‘period data assimilation.

### ğŸ“Repository Layout

```text
.
â”œâ”€â”€ src/               # core implementation
â”‚   â”œâ”€â”€ edm.py         # EDM noise schedule & sampler
â”‚   â”œâ”€â”€ loss.py        # weightedâ€‘conditionalâ€‘Gaussian (WCG) loss
â”‚   â”œâ”€â”€ net.py         # UNet + token crossâ€‘attention
â”‚   â””â”€â”€ train.py       # CLI for train / fineâ€‘tune / infer
â”œâ”€â”€ configs/           # *.yaml experiment recipes
â”œâ”€â”€ data/              # tiny demo arrays + README
â”œâ”€â”€ pics/              # figures used in the paper / README
â”œâ”€â”€ requirements.txt   # pip install â€‘r
â””â”€â”€ README.md
```

## ğŸ“‹Data

| Dataset                        | Native Î”t | Target Î”t | Notes                  | Download                                                     |
| ------------------------------ | --------- | --------- | ---------------------- | ------------------------------------------------------------ |
| ERA5â€‘Land rainfall (1961â€‘2024) | 1â€¯h       | 15â€¯min    | Global 0.1Â° grid       | [https://pan.quark.cn/s/69edae6a321d](https://pan.quark.cn/s/69edae6a321d) |
| NOAAâ€‘20CR v3 RH (1806â€‘2015)    | 3â€¯h       | 15â€¯min    | 1Â° Gaussian grid       | [https://pan.quark.cn/s/69edae6a321d](https://pan.quark.cn/s/69edae6a321d) |
| 2â€‘D DNS cylinder wake          | 0.18â€¯s    | 0.09â€¯s    | Reâ€¯=â€¯80â€“120 test cases | [https://pan.quark.cn/s/69edae6a321d](https://pan.quark.cn/s/69edae6a321d) |

## â³Quick Start

### Install

```bash
  # clone & install
  git clone https://github.com/yourname/time-downscaling.git
  cd time-downscaling
  pip install -r requirements.txt
  conda create -n tdscale python=3.11 -y
  conda activate tdscale
  
  # download data
  bash scripts/fetch_data.sh   # edits PATHS automatically
```

### Train (example: ERA5 2â€¯â†’â€¯1 h)

```bash

# ------------------------------------------------------------------
# A. Twoâ€‘dimensional cylinder wakeğŸŒ (Î”t â†‘ 2Ã—, selfâ€‘supervised)
# ------------------------------------------------------------------
#  â€¢ Trains on Re = 100 wake snapshots    (0.18â€¯s â†’ 0.36â€¯s)
#  â€¢ Evaluates phaseâ€‘sensitive recovery   (reconstruct missing 0.18â€¯s)
python src/train.py --config configs/wake.yaml                # full training
python src/train.py --config configs/wake.yaml --infer        # quick inference on the preâ€‘packed test set

# ------------------------------------------------------------------
# B. ERA5â€‘Land rainfallğŸŒ¦ï¸   (1â€¯h  â†’ 15â€¯min, cascade warmâ€‘start)
# ------------------------------------------------------------------
#  â€¢ Stageâ€‘1: 3â€¯h â†’ 1â€¯h   (weights provided)
#  â€¢ Stageâ€‘2: 1â€¯h â†’ 15â€¯min (this command refines Stageâ€‘2)
python src/train.py --config configs/era5_rainfall.yaml

# ------------------------------------------------------------------
# C. NOAAâ€‘20CRv3 surface RHğŸŒ   (3â€¯h â†’ 15â€¯min, 1806â€‘2015)
# ------------------------------------------------------------------
#  â€¢ Fineâ€‘tunes on the entire 20CR archive in selfâ€‘supervised mode
#  â€¢ Inference below regenerates subâ€‘hourly RH for a single year
python src/train.py --config configs/noaa20_rh.yaml --infer --year 1913
```

## ğŸ’¡ğŸ“ˆModel and Results Overview

![framework](./pics/framework.jpg)![cross](./pics/cross.jpg)

![e](./pics/Re.jpg)

![NOAA20](./pics/NOAA20.jpg)

## ğŸ§ªCitation

@article{Wang2025,
  title  = {Token-Guided Self-Supervised Temporal Reconstruction of Subhourly Climate Dataset since 1806},
  author = {Wang},
  journal= {Nature Machine Intelligence},
  year   = {2025},
}

## ğŸ”“Licence & Contact

This project is released under the MIT licence.
Questions or pullâ€‘requests are welcome:

ğŸŒ GitHub Issues


ğŸ“§ public_wlw@163.com

